# Generated by: Ollama Minimax (llm_router)
# Generated by: Willow (llm_router)

import sys
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

# Insert Willow core path
_WILLOW_CORE_PATH = Path('C:/Users/Sean/Documents/GitHub/aios-minimal')
if str(_WILLOW_CORE_PATH) not in sys.path:
    sys.path.insert(0, str(_WILLOW_CORE_PATH))

import llm_router

PROMPTS_DIR = Path('C:/Users/Sean/Documents/GitHub/aios-minimal/prompts')

def load_template(name: str) -> str:
    """Load a prompt template from the prompts directory."""
    file_path = PROMPTS_DIR / f"{name}.txt"
    with open(file_path, 'r', encoding='utf-8') as f:
        return f.read()

def fill(template: str, **kwargs: Any) -> str:
    """Fill placeholders in the template using kwargs, catching KeyError."""
    try:
        return template.format(**kwargs)
    except KeyError:
        # Return template unchanged if a placeholder is missing
        return template

def ask_with_template(template_name: str, provider_tier: str = 'free', **kwargs: Any) -> Dict[str, Any]:
    """Load a template, substitute placeholders, query the LLM, and return the result."""
    template = load_template(template_name)
    filled_prompt = fill(template, **kwargs)
    response = llm_router.ask(filled_prompt, preferred_tier=provider_tier)
    if response:
        return {'success': True, 'content': response.content, 'provider': response.provider}
    else:
        return {'success': False, 'error': 'Fleet unavailable'}

def log_learning(task: str, provider: str, failure: str, fix: str) -> None:
    """Append a learning entry as a JSON line to fleet_learnings.jsonl."""
    entry = {
        'date': datetime.now().isoformat(),
        'task': task,
        'provider': provider,
        'failure': failure,
        'fix': fix
    }
    log_path = PROMPTS_DIR / 'fleet_learnings.jsonl'
    with open(log_path, 'a', encoding='utf-8', newline='') as f:
        json.dump(entry, f, ensure_ascii=True)
        f.write('\n')