RouterResponse(content='```python\nfrom concurrent.futures import ThreadPoolExecutor\nimport queue\n\ndef process_parallel_chats(tasks):\n    q = queue.Queue()\n    \n    def worker():\n        for task in tasks:\n            local_api.process_smart_stream(task[\'prompt\'], task[\'persona\'])\n            q.put(f"event: {task[\'persona\']}\ndata: [chunk1, chunk2, ...]")\n        \n    with ThreadPoolExecutor() as executor:\n        futures = []\n        for _ in range(5):  # Use a pool size of 5 threads\n            future = executor.submit(worker)\n            futures.append(future)\n            \n        while True:\n            try:\n                event = q.get(block=False)\n                yield event\n                \n                if event == "done_":\n                    persona = event.split("_")[1]\n                    q.put(f"event: {persona}\ndata: [DONE]")\n                    \n                elif event.startswith("event: complete"):\n                    return\n            except queue.Empty:\n                pass\n            \n            # Put a dummy value back in the queue to keep it from emptying too quickly\n            q.put(None)\n```', provider='Ollama', tier='free')
